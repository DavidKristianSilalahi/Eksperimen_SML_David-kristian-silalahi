{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56451eaf",
   "metadata": {},
   "source": [
    "Dataset yang digunakan dalam proyek ini adalah **Iris Dataset** yang merupakan salah satu dataset klasik dalam machine learning.\n",
    "\n",
    "**Sumber Dataset**: Iris dataset tersedia secara built-in dalam scikit-learn library dan juga dapat diperoleh dari UCI ML Repository.\n",
    "\n",
    "**Deskripsi Dataset**:\n",
    "- **Target**: Klasifikasi spesies bunga iris (setosa, versicolor, virginica)\n",
    "- **Features**: 4 fitur numerik (sepal length, sepal width, petal length, petal width)\n",
    "- **Jumlah samples**: 150 samples (50 per kelas)\n",
    "- **Tipe problem**: Multi-class classification\n",
    "\n",
    "Dataset ini dipilih karena:\n",
    "1. Dataset yang bersih dan well-structured\n",
    "2. Cocok untuk pembelajaran machine learning\n",
    "3. Memiliki target yang balanced\n",
    "4. Ukuran yang manageable untuk eksperimen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0cf6b",
   "metadata": {},
   "source": [
    "# **2. Import Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ce3e5",
   "metadata": {},
   "source": [
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library utama\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style untuk visualisasi\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Library berhasil diimport!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b41c5",
   "metadata": {},
   "source": [
    "# **3. Memuat Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7872f",
   "metadata": {},
   "source": [
    "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Dataset Iris akan dimuat menggunakan scikit-learn dan kemudian dikonversi ke format pandas DataFrame untuk analisis yang lebih mudah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset dari scikit-learn\n",
    "iris_data = load_iris()\n",
    "\n",
    "# Konversi ke DataFrame untuk analisis yang lebih mudah\n",
    "iris_df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "iris_df['target'] = iris_data.target\n",
    "iris_df['species'] = iris_df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "# Tampilkan informasi dataset\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(f\"Shape: {iris_df.shape}\")\n",
    "print(f\"Features: {list(iris_data.feature_names)}\")\n",
    "print(f\"Target classes: {list(iris_data.target_names)}\")\n",
    "\n",
    "# Tampilkan beberapa baris pertama\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan raw dataset\n",
    "iris_df.to_csv('../namadataset_raw/iris_raw.csv', index=False)\n",
    "print(\"‚úÖ Raw dataset saved to '../namadataset_raw/iris_raw.csv'\")\n",
    "\n",
    "# Info dataset\n",
    "print(\"\\nüìä Dataset Info:\")\n",
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65911ced",
   "metadata": {},
   "source": [
    "# **4. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.\n",
    "\n",
    "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Statistical Summary\n",
    "print(\"üìä Statistical Summary:\")\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b86a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check untuk missing values\n",
    "print(\"üîç Missing Values Check:\")\n",
    "print(iris_df.isnull().sum())\n",
    "\n",
    "# 3. Check distribusi target\n",
    "print(\"\\nüéØ Target Distribution:\")\n",
    "print(iris_df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f87c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualisasi distribusi features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Feature Distributions', fontsize=16)\n",
    "\n",
    "features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    row, col = i // 2, i % 2\n",
    "    sns.histplot(data=iris_df, x=feature, hue='species', kde=True, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Distribution of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = iris_df[features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Pairplot untuk melihat relationship antar features\n",
    "sns.pairplot(iris_df, hue='species', diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Iris Features by Species', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65cb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Boxplot untuk melihat outliers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Boxplots for Outlier Detection', fontsize=16)\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    row, col = i // 2, i % 2\n",
    "    sns.boxplot(data=iris_df, x='species', y=feature, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Boxplot of {feature} by Species')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3685f9",
   "metadata": {},
   "source": [
    "# **5. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94adc0fc",
   "metadata": {},
   "source": [
    "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.\n",
    "\n",
    "Berdasarkan hasil EDA, kita akan melakukan:\n",
    "1. Feature scaling/standardization\n",
    "2. Train-test split\n",
    "3. Label encoding untuk target (jika diperlukan)\n",
    "4. Menyimpan data yang sudah diproses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare features dan target\n",
    "X = iris_df[features].copy()\n",
    "y = iris_df['target'].copy()\n",
    "\n",
    "print(\"üìä Original Data Shape:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"Target classes: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Memastikan distribusi target seimbang\n",
    ")\n",
    "\n",
    "print(\"üîÑ Train-Test Split Results:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Check distribusi target di train dan test\n",
    "print(\"\\nüìä Target Distribution:\")\n",
    "print(\"Train:\", np.bincount(y_train))\n",
    "print(\"Test:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Konversi kembali ke DataFrame untuk kemudahan\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=features)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=features)\n",
    "\n",
    "print(\"‚öñÔ∏è Feature Scaling Completed!\")\n",
    "print(\"\\nüìä Scaled Features Statistics (Train):\")\n",
    "print(X_train_scaled_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Menyimpan data preprocessing\n",
    "print(\"üíæ Saving preprocessed data...\")\n",
    "\n",
    "# Reset index untuk consistency\n",
    "X_train_scaled_df.reset_index(drop=True, inplace=True)\n",
    "X_test_scaled_df.reset_index(drop=True, inplace=True)\n",
    "y_train_series = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test_series = pd.Series(y_test).reset_index(drop=True)\n",
    "\n",
    "# Simpan ke files\n",
    "X_train_scaled_df.to_csv('namadataset_preprocessing/X_train.csv', index=False)\n",
    "X_test_scaled_df.to_csv('namadataset_preprocessing/X_test.csv', index=False)\n",
    "y_train_series.to_csv('namadataset_preprocessing/y_train.csv', index=False, header=['target'])\n",
    "y_test_series.to_csv('namadataset_preprocessing/y_test.csv', index=False, header=['target'])\n",
    "\n",
    "# Simpan juga complete processed dataset\n",
    "processed_df = iris_df.copy()\n",
    "processed_df[features] = scaler.fit_transform(processed_df[features])\n",
    "processed_df.to_csv('namadataset_preprocessing/iris_preprocessed.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Preprocessed data saved to 'namadataset_preprocessing/' folder\")\n",
    "print(\"üìÅ Files created:\")\n",
    "print(\"   - X_train.csv\")\n",
    "print(\"   - X_test.csv\")\n",
    "print(\"   - y_train.csv\")\n",
    "print(\"   - y_test.csv\")\n",
    "print(\"   - iris_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9521214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Validasi preprocessing dengan simple model\n",
    "print(\"üß™ Validation dengan simple Random Forest:\")\n",
    "\n",
    "# Train simple model untuk validasi\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict dan evaluate\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['setosa', 'versicolor', 'virginica']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1d41b",
   "metadata": {},
   "source": [
    "## **Summary**\n",
    "\n",
    "**‚úÖ Eksperimen berhasil diselesaikan dengan hasil:**\n",
    "\n",
    "1. **Dataset**: Iris dataset (150 samples, 4 features, 3 classes)\n",
    "2. **EDA**: Tidak ada missing values, distribusi target seimbang\n",
    "3. **Preprocessing**: \n",
    "   - Feature scaling menggunakan StandardScaler\n",
    "   - Train-test split (80-20) dengan stratified sampling\n",
    "   - Data tersimpan dalam format CSV\n",
    "4. **Validasi**: Model sederhana mencapai accuracy tinggi\n",
    "\n",
    "**üìÅ Output Files:**\n",
    "- Raw dataset: `../namadataset_raw/iris_raw.csv`\n",
    "- Processed files di `namadataset_preprocessing/`:\n",
    "  - `X_train.csv`, `X_test.csv`\n",
    "  - `y_train.csv`, `y_test.csv` \n",
    "  - `iris_preprocessed.csv`\n",
    "\n",
    "**üéØ Data siap digunakan untuk tahap modeling!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
